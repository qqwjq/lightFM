{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommending questions on CrossValidated\n",
    "In this example, we'll try to recommend questions to be answered to users of stats.stackexchange.com.\n",
    "\n",
    "## Loading the data\n",
    "The full CrossValidated dataset is available at https://archive.org/details/stackexchange. Helper functions to obtain and process it are defined in `data.py`, and we are going to use them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import data\n",
    "\n",
    "(interactions, question_features,\n",
    " user_features, question_vectorizer,\n",
    " user_vectorizer) = data.read_data() # This will download the data if not present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`interactions` is a matrix with entries equal to 1 if the i-th user posted an answer to the j-th question; the goal is to recommend the questions to users who might answer them. \n",
    "\n",
    "`question_features` is a sparse matrix containing question metadata in the form of tags. `vectorizer` is a `sklearn.feature_extraction.DictVectorizer` instance that translates the tags into vector form.\n",
    "\n",
    "`user_features` and `user_vectorizer` pertain to user features. In this case, we take users' 'About' sections: short snippets of natural language that (often) describe a given user's interests.\n",
    "\n",
    "Printing the matrices show that we have around 3200 users and 40,000 questions. Questions are described by one or more tags from a set of about 1200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<3212x40371 sparse matrix of type '<type 'numpy.int32'>'\n",
      "\twith 57891 stored elements in Compressed Sparse Row format>\n",
      "<40371x1189 sparse matrix of type '<type 'numpy.int32'>'\n",
      "\twith 151020 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(interactions))\n",
    "print(repr(question_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tags matrix contains rows such as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'elicitation': 1, 'prior': 1, 'intercept': 1, 'bayesian': 1}, {'intercept': 1, 'distributions': 1, 'normality': 1}, {'intercept': 1, 'open-source': 1, 'software': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(question_vectorizer.inverse_transform(question_features[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User features are exactly what we would expect from processing raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'website': 1, 'blog': 1, 'and': 1, 'user_id:3': 1, 'genetics': 1, 'hunting': 1, 'job': 1, 'university': 1, 'vanderbilt': 1, 'find': 1, 'will': 1, 'near': 1, 'finishing': 1, 'human': 1, 'year': 1, 'end': 1, 'the': 1, 'twitter': 1}]\n"
     ]
    }
   ],
   "source": [
    "print(user_vectorizer.inverse_transform(user_features[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models\n",
    "### Train/test split\n",
    "\n",
    "We can split the dataset into train and test sets by using utility functions defined in model.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def train_test_split(interactions):\n",
      "\n",
      "    train = interactions.copy()\n",
      "    test = interactions.copy()\n",
      "\n",
      "    for i in range(len(train.data)):\n",
      "        if random.random() < 0.2:\n",
      "            train.data[i] = 0\n",
      "        else:\n",
      "            test.data[i] = 0\n",
      "\n",
      "    train.eliminate_zeros()\n",
      "    test.eliminate_zeros()\n",
      "\n",
      "    return train, test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import model\n",
    "import inspect\n",
    "print(inspect.getsource(model.train_test_split))\n",
    "train, test = model.train_test_split(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traditional MF model\n",
    "Let's start with a traditional collaborative filtering model that does not use any metadata. We can do this using `lightfm` -- we simply do not pass in any metadata matrices. We'll use the following function to train a WARP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fit_lightfm_model(interactions, post_features=None, user_features=None, epochs=30):\n",
      "\n",
      "    model = lightfm.LightFM(loss='warp',\n",
      "                            learning_rate=0.01,\n",
      "                            learning_schedule='adagrad',\n",
      "                            user_alpha=0.0001,\n",
      "                            item_alpha=0.0001,\n",
      "                            no_components=30)\n",
      "\n",
      "    model.fit(interactions,\n",
      "              item_features=post_features,\n",
      "              user_features=user_features,\n",
      "              num_threads=4,\n",
      "              epochs=epochs)\n",
      "\n",
      "    return model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(model.fit_lightfm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mf_model = model.fit_lightfm_model(train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will compute the AUC score on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def auc_lightfm(model, interactions, post_features=None, user_features=None):\n",
      "\n",
      "    no_users, no_items = interactions.shape\n",
      "\n",
      "    pid_array = np.arange(no_items, dtype=np.int32)\n",
      "\n",
      "    scores = []\n",
      "\n",
      "    for i in range(interactions.shape[0]):\n",
      "        uid_array = np.empty(no_items, dtype=np.int32)\n",
      "        uid_array.fill(i)\n",
      "        predictions = model.predict(uid_array,\n",
      "                                    pid_array,\n",
      "                                    item_features=post_features,\n",
      "                                    user_features=user_features,\n",
      "                                    num_threads=4)\n",
      "        y = np.squeeze(np.array(interactions[i].todense()))\n",
      "\n",
      "        try:\n",
      "            scores.append(roc_auc_score(y, predictions))\n",
      "        except ValueError:\n",
      "            # Just one class\n",
      "            pass\n",
      "\n",
      "    return sum(scores) / len(scores)\n",
      "\n",
      "0.421300275439\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(model.auc_lightfm))\n",
    "mf_score = model.auc_lightfm(mf_model, test)\n",
    "print(mf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops. That's worse than random (due possibly to overfitting).\n",
    "\n",
    "In this case, this is because the CrossValidated dataset is very sparse: there just aren't enough interactions to support a traditional collaborative filtering model. In general, we'd also like to recommend questions that have no answers yet, making the collaborative model doubly ineffective.\n",
    "\n",
    "### Content-based model\n",
    "To remedy this, we can try using a content-based model. The following code uses question tags to estimate a logistic regression model for each user, predicting the probability that a user would want to answer a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def fit_content_models(interactions, post_features):\n",
      "\n",
      "    models = []\n",
      "\n",
      "    for user_row in interactions:\n",
      "        y = np.squeeze(np.array(user_row.todense()))\n",
      "\n",
      "        model = LogisticRegression(C=0.4)\n",
      "        try:\n",
      "            model.fit(post_features, y)\n",
      "        except ValueError:\n",
      "            # Just one class\n",
      "            pass\n",
      "\n",
      "        models.append(model)\n",
      "\n",
      "    return models\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(model.fit_content_models))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this and evaluating the AUC score gives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_models = model.fit_content_models(train, question_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.662672376323\n"
     ]
    }
   ],
   "source": [
    "content_score = model.auc_content_models(content_models, test, question_features)\n",
    "print(content_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit better, but not great. In addition, a linear model of this form fails to capture tag similarity. For example, `probit` and `logistic regression` are closely related, yet the model will not automatically infer knowledge of one knowledge of the other. \n",
    "### Hybrid LightFM model\n",
    "What happens if we estimate theLightFM model _with_ question features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.709716075859\n"
     ]
    }
   ],
   "source": [
    "lightfm_model = model.fit_lightfm_model(train, post_features=question_features)\n",
    "lightfm_score = model.auc_lightfm(lightfm_model, test, post_features=question_features)\n",
    "print(lightfm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add user features on top for a small additional improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.712266019394\n"
     ]
    }
   ],
   "source": [
    "lightfm_model = model.fit_lightfm_model(train, post_features=question_features,\n",
    "                                         user_features=user_features)\n",
    "lightfm_score = model.auc_lightfm(lightfm_model, test, post_features=question_features,\n",
    "                                  user_features=user_features)\n",
    "print(lightfm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a bit better, illustrating the fact that an embedding-based model can capture more interesting relationships between content features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature embeddings\n",
    "One additional advantage of metadata-based latent models is that they give us useful latent representations of the metadata features themselves --- much in the way word embedding approaches like word2vec.\n",
    "\n",
    "The code below takes an input CrossValidated tag and finds tags that are close to it (in the cosine similarity sense) in the latent embedding space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def similar_tags(model, vectorizer, tag, number=10):\n",
      "\n",
      "    tag_idx = vectorizer.vocabulary_[tag]\n",
      "\n",
      "    tag_embedding = model.item_embeddings[tag_idx]\n",
      "\n",
      "    sim = (np.dot(model.item_embeddings, tag_embedding)\n",
      "           / np.linalg.norm(model.item_embeddings, axis=1))\n",
      "\n",
      "    return np.array(vectorizer.get_feature_names())[np.argsort(-sim)[1:1 + number]].tolist()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(model.similar_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's demonstrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags similar to bayesian:\n",
      "['mcmc', 'prior', 'markov-chain', 'jeffreys-prior', 'subject-specific']\n",
      "Tags similar to regression:\n",
      "['multiple-regression', 'panel-data', 'geomarketing', 'logistic', 'multicollinearity']\n",
      "Tags similar to survival:\n",
      "['cox-model', 'disease', 'epidemiology', 'matching', 'disaggregation']\n",
      "Tags similar to p-value:\n",
      "['t-test', 'scatterplot', 'proportion', 'statistical-significance', 'hypothesis-testing']\n"
     ]
    }
   ],
   "source": [
    "for tag in ['bayesian', 'regression', 'survival', 'p-value']:\n",
    "    print('Tags similar to %s:' % tag)\n",
    "    print(model.similar_tags(lightfm_model, question_vectorizer, tag)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
